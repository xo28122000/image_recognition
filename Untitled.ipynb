{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Simple Way of Solving an Object Detection Task (using Deep Learning)\n",
    "\n",
    "1. First, we take an image as input:\n",
    "2. Then we divide the image into various regions:\n",
    "3. We will then consider each region as a separate image.\n",
    "4. Pass all these regions (images) to the CNN and classify them into various classes.\n",
    "5. Once we have divided each region into its corresponding class, we can combine all these regions to get the original image with the detected objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# definitions :::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(filename):\n",
    "    imgfiles = (glob.glob(filename))\n",
    "    print(len(imgfiles))\n",
    "    images = []\n",
    "    i=1\n",
    "    for imgfile in imgfiles:\n",
    "        image = (cv.imread(imgfile,0))\n",
    "#         because there are two different dimentions in the data of images 256 250 where 256 has a majority count\n",
    "        if(np.shape(image) == (256,256)):\n",
    "            images.append(image)\n",
    "        \n",
    "#         clear output\n",
    "        if(i%50 == 0):\n",
    "            clear_output()\n",
    "        print(i,end=\"  \")\n",
    "        i+=1\n",
    "       \n",
    "        \n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(filename):\n",
    "    imgfiles = (glob.glob(filename))\n",
    "    print(len(imgfiles))\n",
    "    for imgfile in imgfiles:\n",
    "        image = (cv.imread(imgfile,0))\n",
    "        try:\n",
    "            reimage = cv.resize(image,(100,100))\n",
    "            cv.imwrite(imgfile,reimage)\n",
    "        except Exception as ex:\n",
    "            print(\"problem in :\" + imgfile)\n",
    "            print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_dimention(convlist):\n",
    "    for i in range(0,len(convlist)):\n",
    "        convlist[i] = convlist[i].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resizing images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6899\n"
     ]
    }
   ],
   "source": [
    "resize_images(\"/Users/j/Desktop/programming/ML/github/image_recognition/data/kaggle_datasets/natural_images/*/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction :::::::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950  951  952  953  954  955  956  957  958  959  960  961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976  977  978  979  980  981  982  983  984  985  986  "
     ]
    }
   ],
   "source": [
    "person_data_train = read_images(\"/Users/j/Desktop/programming/ML/github/image_recognition/data/kaggle_datasets/natural_images/person/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750  751  752  753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768  769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784  785  786  787  788  "
     ]
    }
   ],
   "source": [
    "motorbike_data_train = read_images(\"/Users/j/Desktop/programming/ML/github/image_recognition/data/kaggle_datasets/natural_images/motorbike/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000  "
     ]
    }
   ],
   "source": [
    "fruit_data_train = read_images(\"/Users/j/Desktop/programming/ML/github/image_recognition/data/kaggle_datasets/natural_images/fruit/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800  801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816  817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832  833  834  835  836  837  838  839  840  841  842  843  "
     ]
    }
   ],
   "source": [
    "flower_data_train = read_images(\"/Users/j/Desktop/programming/ML/github/image_recognition/data/kaggle_datasets/natural_images/flower/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700  701  702  "
     ]
    }
   ],
   "source": [
    "dog_data_train = read_images(\"/Users/j/Desktop/programming/ML/github/image_recognition/data/kaggle_datasets/natural_images/dog/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "850  851  852  853  854  855  856  857  858  859  860  861  862  863  864  865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880  881  882  883  884  885  "
     ]
    }
   ],
   "source": [
    "cat_data_train = read_images(\"/Users/j/Desktop/programming/ML/github/image_recognition/data/kaggle_datasets/natural_images/cat/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950  951  952  953  954  955  956  957  958  959  960  961  962  963  964  965  966  967  968  "
     ]
    }
   ],
   "source": [
    "car_data_train = read_images(\"/Users/j/Desktop/programming/ML/github/image_recognition/data/kaggle_datasets/natural_images/car/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700  701  702  703  704  705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720  721  722  723  724  725  726  727  "
     ]
    }
   ],
   "source": [
    "airplane_data_train = read_images(\"/Users/j/Desktop/programming/ML/github/image_recognition/data/kaggle_datasets/natural_images/airplane/*.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data maniputation:::::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_dimention(person_data_train)\n",
    "linear_dimention(motorbike_data_train)\n",
    "linear_dimention(fruit_data_train)\n",
    "linear_dimention(flower_data_train)\n",
    "linear_dimention(dog_data_train)\n",
    "linear_dimention(cat_data_train)\n",
    "linear_dimention(car_data_train)\n",
    "linear_dimention(airplane_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(motorbike_data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [X, y]\n",
       "Index: []"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdatadf = pd.DataFrame({\n",
    "    'X':person_data_train,\n",
    "    'y': [1 for x in range(len(person_data_train))]\n",
    "})\n",
    "mdatadf = pd.DataFrame(\n",
    "        {\n",
    "    'X':motorbike_data_train,\n",
    "    'y': [2 for x in range(len(motorbike_data_train))]\n",
    "        })\n",
    "mdatadf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chaeking i got correct dimentions of each image\n",
    "\n",
    "# checkshape = []\n",
    "# for pt in person_data_train:\n",
    "#     checkshape.append(np.shape(pt))\n",
    "# np.unique(checkshape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(person_data_train)\n",
    "Y = np.ones(len(person_data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=0.001,hidden_layer_sizes=(10, 8), random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(983, 65536)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(983,)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtype \n",
    "#  the error that i was facing was that i made a 2d array with first row as my x abnd \n",
    "# second as my y as when i tried to input that i was getting an error as the dtype of that was 'o' - object dtype.\n",
    "# so i seperated the values of X and Y in two different np arrays and it isworking\n",
    "\n",
    "#  always check the dtype and size of the arry.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(10, 8), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=1, shuffle=True, solver='lbfgs', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, Y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tests ::::::::::::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### primary test.\n",
    "\n",
    "with people's faces only \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "problem in :/Users/j/Desktop/programming/ML/github/image_recognition/data/kaggle_datasets/natural_images/person/scrapped_tests/5.jp2\n",
      "OpenCV(4.0.0) /Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/resize.cpp:3784: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n",
      "problem in :/Users/j/Desktop/programming/ML/github/image_recognition/data/kaggle_datasets/natural_images/person/scrapped_tests/backup\n",
      "OpenCV(4.0.0) /Users/travis/build/skvark/opencv-python/opencv/modules/imgproc/src/resize.cpp:3784: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resize_images(\"/Users/j/Desktop/programming/ML/github/image_recognition/data/kaggle_datasets/natural_images/person/scrapped_tests/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "1  2  3  4  5  6  7  8  9  10  11  "
     ]
    }
   ],
   "source": [
    "test1_x = read_images(\"/Users/j/Desktop/programming/ML/github/image_recognition/data/kaggle_datasets/natural_images/person/scrapped_tests/*\")\n",
    "linear_dimention(test1_x)\n",
    "test1_X = np.array(test1_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 65536)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test1_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(test1_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
